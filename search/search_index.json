{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-safer-streets-leeds","title":"Welcome to Safer Streets @ Leeds","text":"<p>This is where you will find articles chronicling our deliverables and research, and other resources...</p> <p>Work in progress</p> <p>Please note this site is not yet fully operational...</p>"},{"location":"#resources","title":"Resources","text":""},{"location":"#blog","title":"Blog","text":""},{"location":"#apps","title":"Apps","text":"<p> Crime Concentration Explorer Demo App</p>"},{"location":"#repositories","title":"Repositories","text":"<p>See the github org page for instructions on getting set up for development</p> <p> safer-streets-eda - exploratory (public) data analysis</p> <p> safer-streets-apps - applications</p> <p> safer-streets-core - common functionality: crime, demographic and geospatial data extraction and manipulation, statistical methods</p> <p> site - sources for this site</p>"},{"location":"references/","title":"References","text":"<p>TODO...</p>"},{"location":"blog/","title":"Recent Posts","text":""},{"location":"blog/tags/","title":"Tags","text":""},{"location":"blog/tags/#tag:crime-hotspots","title":"Crime hotspots","text":"<ul> <li>            Scaling Up          </li> </ul>"},{"location":"blog/tags/#tag:explainer","title":"Explainer","text":"<ul> <li>            Crime prevention features          </li> <li>            Why is all this maths important?          </li> </ul>"},{"location":"blog/tags/#tag:gini-coefficient","title":"Gini coefficient","text":"<ul> <li>            Crime Concentration Explorer          </li> <li>            Measuring Crime Concentration (Part 1)          </li> <li>            Measuring Crime Concentration (Part 2)          </li> </ul>"},{"location":"blog/tags/#tag:lorenz-curve","title":"Lorenz curve","text":"<ul> <li>            Crime Concentration Explorer          </li> <li>            Measuring Crime Concentration (Part 1)          </li> <li>            Measuring Crime Concentration (Part 2)          </li> </ul>"},{"location":"blog/tags/#tag:poisson-distribution","title":"Poisson distribution","text":"<ul> <li>            Measuring Crime Concentration (Part 1)          </li> <li>            Measuring Crime Concentration (Part 2)          </li> </ul>"},{"location":"blog/tags/#tag:public-crime-data","title":"Public crime data","text":"<ul> <li>            Crime Concentration Explorer          </li> </ul>"},{"location":"blog/tags/#tag:duckdb","title":"duckdb","text":"<ul> <li>            Scaling Up          </li> </ul>"},{"location":"blog/tags/#tag:streamlit","title":"streamlit","text":"<ul> <li>            Crime Concentration Explorer          </li> </ul>"},{"location":"blog/author/team/","title":"The Safer Streets Team","text":"<p>Daniel Birks, Professor of Computational Social Science, University of Leeds</p> <p> profile</p> <p>Toby Davies, Associate Professor in Criminal Justice Data Analytics, University of Leeds</p> <p> profile</p> <p>Andrew Smith, Senior Research Fellow, University of Leeds</p> <p> profile</p>"},{"location":"blog/2025/08/11/crime-concentration-explorer/","title":"Crime Concentration Explorer","text":"","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/11/crime-concentration-explorer/#rationale","title":"Rationale","text":"<p>This app has been built as a proof-of-concept tool for practitioners and policymakers with an interest in the patterns of crime concentration, using only publicly available data. It enables users to visualise crime hotspots over time for a given Police Force Area (PFA).</p> <p>The use of public data (crime data from data.police.uk) imposes some limitations: although we have precise (albeit slightly perturbed) location data, we only have rough temporal information (the month the crime occurred) and a dozen or so broad categories of crime. The Safer Streets project is concerned specifically with antisocial behaviour (ASB), knife crime and violence against women and girls (VAWG). While ASB is represented in the data, the demo app proxies the broader Possession of weapons and Violence and sexual offences categories for knife crime and VAWG.</p> <p>Users can select the PFA, crime type, spatial units, the degree of concentration<sup>1</sup>, then run the analysis over 3 years or inspect specific months. Counts per spatial unit are displayed on an interactive map and, optionally, a Lorenz curve is shown. The Gini coefficient is displayed.</p>","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/11/crime-concentration-explorer/#implementation","title":"Implementation","text":"<p>The app is built in the python streamlit framework, using pydeck for map visualisations and altair for graphs.</p> <p>Data is handled using pandas and geopandas for geospatial data.</p> <p>Whilst the raw crime data is cached, aggregation to spatial units is done on-the-fly. The smaller the spatial units, the longer this will take.</p> <p>The code for the demo app is here</p>","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/11/crime-concentration-explorer/#limitations","title":"Limitations","text":"<p>The app is currently deployed on Streamlit's own free-tier cloud which imposes limitations on total app size (including data). To keep within this limit the data available to the demo app has been restricted:</p> <ul> <li>West Yorkshire PFA only</li> <li>the choice of spatial unit is restricted (notably omitting output areas and street segments)</li> <li>3 years of crime data</li> </ul> <p>Additionally, due to the use of public data, temporal resolution is limited to monthly units.</p>","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/11/crime-concentration-explorer/#further-work","title":"Further work","text":"<p>The demo app was implemented within the exploratory data analysis (EDA) repo, as it required many of the code components developed there. Those components and the app itself have been factored out into separate repos, which will simplify future deployment.</p> <p>A full-fat version of the app with full datasets will be provided when we have suitable cloud provisioning.</p>","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/11/crime-concentration-explorer/#link","title":"Link","text":"<p>Try the app for yourself!</p> <p> https://crime-concentration-explorer.streamlit.app/</p> <ol> <li> <p>this refers to the smallest set of spatial units - i.e. those with most crime - that contain a set percentage of the total crime for a given month. For example, you may be able to capture 50% of crime in only 5% of spatial units.\u00a0\u21a9</p> </li> </ol>","tags":["streamlit","Public crime data","Gini coefficient","Lorenz curve"]},{"location":"blog/2025/08/27/crime-prevention-features/","title":"Crime prevention features","text":"","tags":["Explainer"]},{"location":"blog/2025/08/27/crime-prevention-features/#understanding-the-dimensions-of-crime-prevention-interventions","title":"Understanding the Dimensions of Crime Prevention Interventions","text":"<p>Crime prevention interventions can be characterised in many different ways. The College of Policing\u2019s Crime Reduction Toolkit and its underpinning EMMIE framework provide a robust approach for assessing what works to reduce crime. But applying that knowledge in practice requires us to think carefully about how specific interventions will interact with the spatial and temporal characteristics of the problems they are intended to address. Understanding not just whether something works, but where, when, and under what conditions, is crucial for matching interventions to the dynamics of crime on the ground.</p> <p>To illustrate this, consider two contrasting approaches: foot patrol and hotspot problem-solving.</p> <p>Foot patrol can be deployed quickly in small, targeted areas. It tends to have immediate but short-lived effects, and its impact is usually limited to specific offence types in the area directly patrolled. This can make it a good fit for transient hotspots - places where crime temporarily flares up and needs rapid, visible deterrence.</p> <p>Patrol exemplifies interventions that are quick to start but quick to fade, suited to problems that move or evolve rapidly.</p> <p>By contrast, hotspot problem-solving - a form of Problem-Oriented Policing (POP) often delivered through tailored situational crime prevention measures - is designed for persistent, stable hotspots. This approach focuses on diagnosing the underlying causes of recurring problems and implementing changes to the environment, management practices, or local routines. Examples include improved lighting, access control, street layout changes, or co-ordinated multi-agency activity.</p> <p>Such approaches require time: time to analyse patterns of harm, time to co-design a response with partners, and time for the intervention to take effect. But once implemented, their impact can be durable, altering the conditions that allow the problem to persist. As such, POP is better suited to relatively stable hotspots where problems persist long enough to allow for effective diagnosis and implementation. In more dynamic environments,  where problems shift rapidly in space or time, the delay inherent in this approach can make it harder to intervene before the issue has moved elsewhere.</p> <p>Hotspot problem-solving therefore contrasts with patrol as an intervention that is slow to start but long to last.</p> <p>Both strategies can be effective - but only when matched to the right context. To make informed decisions then, we need to understand the different dimensions that shape how, where, and why an intervention might work.</p> <p>That\u2019s why, when designing or assessing crime prevention interventions and how they may or may not match up with the crime problems we seek to adress, we probably need to ask a series of guiding questions to understand their underlying dimensions. These include practical constraints (such as cost and scalability), theoretical fit (the nature of the problem being targeted), and delivery characteristics (such as how quickly the intervention takes effect and how long evidence suggests its impact will last). Crucially, we need to consider how an intervention is likley to align with the spatial and temporal patterns of the problem in question: whether the issue is concentrated in a few persistent hotspots or is more dispersed and short-lived. Matching the scale and timing of an intervention to the observed distribution and dynamics of harm is essential for ensuring that resources are deployed effectively and sustainably.</p> <p>Below is the (non-exhaustive) set of guiding questions we envisage being useful when reviewing interventions:</p> <ul> <li> <p>What is the intervention? </p> </li> <li> <p>What type of offence is it targeting? The specific crime or harm the intervention is designed to address (e.g. ASB, knife crime, VAWG).</p> </li> <li> <p>At what level or unit is it delivered? The spatial or institutional scale of implementation (e.g. street, school, neighbourhood).</p> </li> <li> <p>How strong is the evidence that it works? What is the quality and consistency of the evidence supporting its effectiveness (e.g. RCTs, evaluations, expert consensus)?</p> </li> <li> <p>How long do the effects last? After the intervention ends, for how long do its effects persist?</p> </li> <li> <p>How quickly does it start working? What is the typical time lag between implementation and observable impact?</p> </li> <li> <p>Roughly how much reduction in harm or crime might we expect? Based on available evaluations, what is the typical scale of change achieved (e.g. 10\u201320% reduction)?</p> </li> <li> <p>Do the benefits spill over into nearby areas? Does the intervention show signs of producing positive effects beyond the targeted unit (i.e. diffusion of benefit)?</p> </li> <li> <p>How much does it cost to deliver per unit? The estimated financial cost to implement one instance of the intervention, including staff time, materials, and overheads.</p> </li> <li> <p>What might be potnetial unintended consequences? Some interventions have either been shown to generate uninentended consequences - or those consequences can be somewhat anticipated. </p> </li> <li> <p>How many units could we treat? Given a typical funding/resource envelope, how many units (e.g. schools, streets, hotspots) could be feasibly covered?</p> </li> </ul> <p>We also know that the quality of evidence available to answer some of these questions can vary significantly across different interventions. That\u2019s where a framework like EMMIE can help,  by encouraging a structured assessment not just intervention effectiveness. Ultimately, understanding these dimensions helps decision-makers move beyond simply asking \u201cdoes it work?\u201d to asking \u201cwhat works, for whom, in what contexts, and at what cost?\u201d Only by engaging with these trade-offs can we design more effective, targeted, and scalable responses to crime. </p>","tags":["Explainer"]},{"location":"blog/2025/09/15/demographics/","title":"Demographics","text":"<p>When we look at crime counts at different spatial scales, it is often useful to try to understand the demographics of the area. Older people are more likely to be victims of certain crimes, for instance, and for others there are often correlations between crime incidence and the deprivation, socioeconomic status or other makeup of the area.</p> <p>The UK census is the biggest source of demographic data, providing many attributes over various spatial scales. With census data there is always a tradeoff between spatial and categorical resolutions, often to preserve anonymity. For example, the highest spatial resolution for counts of people by age in years is MSOA, and at higher resolutions (LSOA, OA) age is only given in 5-year bands.</p> <p>Another very important consideration is that we will want to aggregate people to non-statistical geographies, such as grids and hexes. In order to do this, we could simply place people at random points within the statistical geography, then take those that fall within the new geography. However this can be unrealistic, particularly in areas that are rural or contain large-scale non-residential infrastructure or bodies of water (despite Monty Python's boasts, nobody in Yorkshire lives under a lake!).</p> <p>To do this reasonably accurately we need to have some idea of the geography within the areas, to avoid placing people in nonsensical locations. One way to achieve this is to use the street network. OSM provide detailed street networks including classifications, so we can even limit to certain types of streets - i.e. residential - making the assignment even more realistic.</p> <p>The next step is to place people onto the (residential) street network</p>"},{"location":"blog/2025/09/15/demographics/#example","title":"Example","text":"<p>We want to realistically re-aggregate the population of the census output area E00053954 to a 250m hex grid.</p> <p>This output area has been deliberately chosen as it covers a relatively very large 11km\u00b2 (compared to the West Yorkshire average of 0.28km\u00b2, and the hex cell area of 0.16km\u00b2) with a very uneven population distribution.</p> <p>It has a population of 293 (West Yorkshire average is 320). Most of this area is uninhabited moorland, and is crossed by largely non-residential main roads. Residential streets are clustered in the east of the area (shown in red in the map below).</p> <p></p> <p>The methodology we use is a three-step process:</p> <ol> <li>using appropriate census table(s), generate a population with the required attributes (e.g. age, sex, ethnicity, socioeconomic status) consistent with the totals for the output area</li> <li>assign each person to a randomly sampled point on the street network within the output  area.</li> <li>spatially join the points with the new features and aggregate as required</li> </ol> <p>This is relatively efficient: as the first two steps are independent of the choice of new feature, the population data from step 2 can be cached and reused.</p> <p>Using the example output area above, this would result in the population of 293 people being assigned to hexes like so:</p> <p></p> <p>Although this illustrative example only covers a single output area, in practice, the assignment is carried out over an entire Police Force Area, and, rather than having truncated grid cells on the edges of output areas, population is be assigned to the full cell from all the intersecting output areas.</p>"},{"location":"blog/2025/09/15/demographics/#limitations","title":"Limitations","text":"<p>This methodology treats each individual separately and cannot capture households or clusters of individuals with shared traits (such as ethnicity). Census data does not capture any spatial heterogeneity of categorical features within the output area.</p> <p>People are assigned locations at random on street segments that are classified as residential, except for the occasional cases where output areas contain no residential streets (e.g. communal residences) - where people are just assigned random locations within the output area.</p>"},{"location":"blog/2025/09/15/demographics/#further-development","title":"Further Development","text":"<p>If retaining household structure became desirable, the census does provide household-level statistics and locations of people could be grouped accordingly. Another possibility is to use OSM building data rather that street data - but at the time of writing the data quality is an issue, with missing data and inconsistent building classifications.</p>"},{"location":"blog/2025/07/30/introducing-safer-streets/","title":"Introducing Safer Streets","text":"<p>Welcome! </p> <p>Here you will find:</p> <ul> <li>blog articles</li> <li>links to interactive tools we have developed/are developing</li> <li>links to github repos containing:<ul> <li>jupyter notebooks and code used in the analysis of crime data.</li> <li>source code for the interactive tools</li> </ul> </li> <li>Team bios</li> </ul>"},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/","title":"Measuring Crime Concentration (Part 2)","text":"<p>We demonstrated in part 1 that random data with no structural concentration will exhibit some concentration using the traditional measures. In this article we taker a deeper dive into this claim.</p> <p>Recall that our null hypothesis was that crimes are not concentrated, crime is is no more or less likely to occur in any given spatial unit, and the chance of a crime occurrence is not affected by previous events.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#motivating-example-seasonality","title":"Motivating example - Seasonality","text":"<p>Public crime data in the UK contains precise (but obfuscated) location data, imprecise temporal information (the month of occurrence) and broad categorical information (around a dozen categories). Taking 3 years of data for incidents of ASB in West Yorkshire, aggregating crime into spatial units (in this case LSOA) we can plot a graph of (naive) Gini over time.</p> <p>This graph shows some clear seasonality - concentration increases in the winter and decreases in the summer. A fairly obvious explanation for this would be that since antisocial behaviour generally occurs outdoors, there are simply more outdoor gatherings in warmer weather and longer daylight hours, therefore more opportunities.</p> <p></p> <p>However, more careful analysis of the data shows the apparent seasonality is an illusion. Here's why...</p> <p>Put in statistical terms, our null hypothesis is that crime counts in each spatial unit are i.i.d Poisson processes, with intensity \\(\\lambda = C / N\\) where \\(C\\) is the total number of crimes and \\(N\\) the number of spatial units. In other words each spatial unit is identical in terms of its propensity to contain crime.</p> <p>For the dataset in question, \\(\\lambda\\) ranges between 0.82 and 2.26 over the 3 years. Since in most cases \\(\\lambda \\ge 1\\), the adjustment suggested by Bernasco and Steenbeck (see part 1) would have no effect.</p> <p>A comparison of actual vs sampled crimes - both Lorenz curves and Gini coefficient - broadly shows what we expect: actual crime data is more concentrated than sampled data and the sampled data appears to show some level of concentration.</p> <p></p> <p>But the most interesting point to note is that the sampled data appears to share the seasonality of concentration of the real data, and if you compute the \"excess\" Gini by subtracting the sampled Gini from the actual Gini values, the seasonality disappears, in fact the \"excess\" is negatively correlated with naive Gini, suggesting - if anything - the opposite of our original explanation.</p> <p>But since we know the sampled data is not concentrated (by construction) we must conclude that there is no (strong) seasonality in the actual data. The variation we observe is (almost) entirely due to a seasonality in count data, that is, there are simply fewer incidents of ASB, and because our concentration metric is flawed, it appears as an increase in concentration. This is clear from a scatterplot of Gini against total crimes in each month:</p> <p></p> <p>Now, going back to the null hypothesis, we have a range of counts and we could compute a null-hypothesis Lorenz curve for each, but it probably makes more practical sense to compute bounds on the Lorenz curves we would expect under the null hypothesis. Repeating the graph from above yields</p> <p></p> <p>There is little discernable difference from the analytic null-hypothesis Gini and the sampled Gini (as we would expect).</p> <p>Looking at some other crime types - firstly violent crime, which has a much higher incidence (~11000 per month compared to ~2300 for ASB) and no apparent seasonality:</p> <p></p> <p>Here most of the observed concentration is real, as the bias is lower due to the higher incident counts at this spatial scale.</p> <p>Whereas for the less frequent crime of possession of weapons (~210 per month):</p> <p></p> <p>almost all of the apparent concentration arises from the low-observation bias.</p> <p>From here, the next steps are to determine how far along the road to spatial invariance this get us, and also potentially investigate whether it is possible we can improve upon our null hypothesis using a more sophisticated statistical model?</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#scale-invariance","title":"Scale Invariance","text":"<p>Traditional measures of concentration are well-known to not be scale-invariant, and thus making comparisons of count data at different spatial or temporal scales is extremely difficult - smaller scales will always produce higher concentration values, and, importantly, this is true for randomly sampled data.</p> <p>The hope is that by using a concentration measure that compensates for the null hypothesis we will take a step towards scale-invariance. We shall investigate this further in a subsequent post.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#modified-gini","title":"Modified Gini","text":"<p>Naive Gini is given by double the area under the Lorenz curve (1), above the diagonal. This means it can take values between 0 (fully dispersed) and 1 (fully concentrated). Recall the Lorenz curve for ordered discrete count data \\(c(i)\\) of length \\(N\\) is</p> <ol> <li>The convention in criminology is to represent the curve as a plot of cumulative counts from highest to lowest, which \"flips\" (both vertically and horizontally) the form normally seen in fields such as Economics.</li> </ol> \\[ L(x) = \\frac{\\sum_{i=1}^k c(i)} {\\sum_{i=1}^N c(i)} \\] <p>where \\(x=k/N\\) - thus the curve is bounded between \\([0,1]\\) in both the \\(x\\) and \\(y\\) axes, enabling easy comparison between datasets of different sizes.</p> Properties of the Lorenz curve <p>Other important properties arise from the ordering - the curve is bounded by the lines \\(y=x\\) and \\(y=1\\), and must increase monotonically. If it rises above \\(y=x\\) then it must level off - the rate of change of the gradient can only stay the same or decrease:</p> \\[ x \\le L(x) \\le 1, \\quad \\frac{dL(x)}{dx} \\ge 0, \\quad \\frac{d^2L(x)}{dx^2} \\le 0 \\] <p>The Gini coefficient can be computed from the Lorenz curve using the formula:</p> \\[ Gini = 2\\int_0^1{\\big(L(x) - x\\big)}dx \\] <p>We can compute an exact null-hypothesis Lorenz curve from the inverse CDF of the Poisson distribution:</p> \\[ L_0(x) = \\frac{1}{\\lambda}\\int_0^x{F^{-1}(p; \\lambda) dp} \\] Explanation of the formula <p>The theoretical Lorenz curve for independent identically distributed samples is the cumulative sum of inverse CDF \\(F^{-1}(p; \\lambda)\\) of the Poisson distribution</p> \\[ L_0(x) = \\int_0^x{F^{-1}(p; \\lambda) dp} \\bigg/ \\int_0^1{F^{-1}(p; \\lambda) dp} \\] <p>the denominator can be simplified using a change of variables - it is in fact just the mean of the distribution. Since \\(x = F^{-1}(p)\\), \\(p = F(x)\\) and \\(dp=f(x)dx\\) (the PDF). When \\(p=0\\), \\(x=-\\infty\\) and when \\(p=1\\), \\(x=+\\infty\\). Substituting into the denominator produces the expectation, i.e. the mean:</p> \\[ \\int_{-\\infty}^{+\\infty}{xf(x)dx} = E[X] = \\lambda \\] <p>In the Gini formula, the \\(x\\) term represents the maximal dispersion line. we have argued that this line does not represent a reasonable lower bound and should be replaced by the null hypothesis Lorenz curve, resulting in the modified Gini coefficient:</p> \\[ Gini_{modified} = 2\\int_0^1{\\big(L(x) - L_0(x)\\big)}dx \\] <p>which has different properties to naive Gini. Although a value of 1 still represents maximal concentration, 0 now represents the level of concentration expected under the null hypothesis, and negative values can arise if the counts are more dispersed than this. Significant negative values imply some form of mean-reversion mechanism, in practical terms this could imply some level of planning and organisation on the part of perpetrators, or a finite number of dispersed and limited opportunities.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#results","title":"Results","text":"<p>The graphs below depict naive and modified Gini coefficients for simulated (non-concentrated) data matching actual crime counts for the three crimes of varying rates of incidence we have studied, at varying spatial and temporal scales, using census geographies:</p> <p></p> <p>The x-axis is expressed in terms of the count of total crimes in the aggregation period. The periods vary from 1 to 36 months. As expected, our modified Gini measure correctly shows no concentration, whereas the naive Gini measure shows a degree of concentration that varies according to the size of the spatial unit and the total count/temporal scale, demonstrating that is is neither accurate nor consistent and thus not a statistic that can be used for comparison.</p> <p>Turning to the real data, we do (as expected) observe some concentration. The modified Gini is always lower, again as expected, as we knew concentration was being overestimated. As the count/temporal scale increases, the two curves converge on the same value, again as expected. Repeating the analysis for census geographies:</p> <p></p> <p>and also for regular square grids of different sizes</p> <p></p> <p>However, whereas the naive Gini tends to be significantly higher for smaller spatial scales or total counts, the opposite appears to be true for for the modified Gini. This could be because</p> <ol> <li>there is a flaw in the Gini adjustment, and/or...</li> <li>the data actually has a structure where the degree of concentration varies with scales</li> </ol> <p>In order to fully confirm or eliminate these points, we need to investigate how the modified Gini behaves using simulated counts from an over-dispersed distribution. More on that in the next instalment, but in the meantime there are a couple of tests we can carry out to see if the modified Gini is trustworthy:</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#p-value","title":"p-value","text":"<p>The Gini adjustment is based on our null hypothesis that crimes are not concentrated. Therefore we can compute a p-value from a Chi-squared test on the count data, and if the null hypothesis is not rejected (i.e. a p-value above ~0.05) we can say with certainty that the count data is too sparse to measure any meaningful concentration.</p> <p>Consider the extreme case where we have 100 spatial units and a total count of 1. Because we are dealing with discrete quantities the single value must be in a single state. Clearly in this case it is meaningless to attribute a concentration, but Naive Gini will give this a value of 0.99, and modified Gini around 0.</p> <p>If the total count is 2, and the crimes occur in 2 different units, this represents the least concentration possible, yet naive Gini will be 0.98. Modified Gini however, is - correctly - around zero. But conversely, the concentrated case where both events happen in the same spatial unit - naive Gini is 0.99 but modified is a very low ~0.01. However, the p-value tells us that we cannot meaningfully measure concentration for data this sparse</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#skew","title":"Skew","text":"<p>However, even when counts are on the low side, but high enough for the null hypothesis to be rejected, concentration measures are not consistent.</p> <p>The Poisson distribution is highly skewed when the intensity is low, with a value of \\(1/\\sqrt{\\lambda}\\). This creates a bias when sampling from the distribution, or fitting observed values to a Poisson distribution, resulting in a larger adjustment than necessary. One possibility is to incorporate a further adjustment, based on the observed skew (or coefficient of variation) to the modified Gini to compensate for overdispersed low count effects. However, this adds a further level of complexity that could deter adoption of the measure and its usefulness in terms of explainability to wider audiences.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/10/13/measuring-crime-concentration-part-2/#conclusions-and-further-work","title":"Conclusions and Further Work","text":"<ul> <li> <p>Naive Gini overestimates concentration</p> </li> <li> <p>Naive Gini is not comparable across different spatial or temporal scales</p> </li> <li> <p>Even at the same spatio-temporal scale, Naive Gini is not comparable over time when there is variation in unit counts</p> </li> <li> <p>Modified Gini allows more direct comparison between different spatio-temporal, but it also is not scale invariant so care must be taken</p> </li> <li> <p>More work needs to be done to understand how modified Gini behaves when counts are low, especially in the presence of  overdispersion.</p> </li> <li> <p>More work needs to be done on establishing whether Poisson-Gamma can in fact be treated as a useful baseline for Gini adjustment.</p> </li> <li> <p>More work needs to be done on the viability of an \"explainable\" Poisson mixture model. This could be combined with \"zero-inflated\" models (Poisson or NB) that account for an excess of zero counts driven potentially by features of the spatial units.</p> </li> </ul>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/","title":"Measuring Crime Concentration (Part 1)","text":"<p>What constitutes concentration? In these articles we ask:</p> <ul> <li>how do we count crimes? And how do we account for and control for heterogeneity in our observations (units with different area and populations)?</li> <li>how do we decide if crime is concentrated? What measures are traditionally used?</li> <li>if crime is purely random and thus isn't concentrated in any meaningful sense, will we still measure some concentration using traditional measures?</li> <li>can we develop a \"null hypothesis\" statistical model to create a baseline measure, allowing us to differentiate between random and structural effects? What features must this model have to be realistic?</li> <li>how do we develop this into a useful measure?</li> </ul>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#counting-crime","title":"Counting Crime","text":"<p>In the UK, the Police publish monthly crime statistics covering 12 broad categories of crime. The data includes precise geographic information - \"snapped\" coordinates(1) as well as LSOA(2) - but no information on timing other than the month in which it occurred. For the purposes of this article our dataset will be the incidents of antisocial behaviour in West Yorkshire PFA over the last 3 years.</p> <ol> <li> To preserve anonymity the points are snapped to \"snap points\" which are typically the centre of a street segment or a public place</li> <li> LSOA is a hierarchical census geography which controls (to some extent) for resident population, so LSOAs can vary widely in terms of area but less so in terms of population - usually containing 1000-3000 people. LSOAs are aggregations of OAs (Output Areas) and in turn aggregate into MSOAs (Middle layer Super Output Area)</li> </ol> <p>Since perpetrators and victims are people, we'd expect a strong correlation between population and crime counts in given spatial units. But locations also present opportunities for crime, we would also expect to see some correlation between area too.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#aggregation-options","title":"Aggregation Options","text":"<p>Since we have metre-resolution coordinates for each crime we are free to count crimes in any spatial unit of our choice. This boils down to three categories:</p> <ul> <li> <p>statistical geographies that control for population and align to administrative boundaries, but vary widely in size and shape.</p> </li> <li> <p>regular spatial units (grid, hex etc) that have constant area (except where they cross the PFA boundary) but widely varying population. The histograms below highlight the differences between LSOAs with and 1200m square grid (this size results in a similar number of units)</p> </li> <li> <p>the street network. This typically will have the largest number of units - making it computationally more expensive - and has considerable variability in both size and population</p> </li> </ul> <p>Populations of non-statistical Spatial Units</p> <p>Assigning populations to streets or regular spatial units in a realistic way warrants an article of it's own. Watch this space...</p> <p></p> <p>This illustrates how the choice of spatial units has a large impact on the structure of our count data, and in the coming sections we'll see that it has a profound effect on the concentration metrics that are normally used.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#measuring-concentration","title":"Measuring concentration","text":"<p>Once we have crime counts for each of our spatial units, how do we determine whether crime is concentrated? That is, how much of the clustering/clumpiness we observe can be attributed to random fluctuations, and how much is structural in some way? Traditional measures include the Lorenz curve(1), which plots the proportion of space against the proportion  of events</p> <ol> <li> originally used in Economics to measure income disparity - cumulative wealth versus cumulative population.</li> </ol> <p>The steeper the Lorenz curve, the more crime is concentrated in a small number of areas. The Gini coefficient can be used to capture the disparity in a single value - it measures the amount by which the Lorenz curve deviates from a straight line. A straight line represents a perfectly uniform distribution of counts across units.</p> <p>Using Antisocial behaviour in West Yorkshire as an example, the following graphs illustrate the variability of the Lorenz curve and Gini coefficient against different spatial and temporal aggregation scales:</p> <p></p> <p>Unsurprisingly, higher concentrations are observed at higher spatial and temporal resolutions. But this does not necessarily imply a structural concentration mechanism: after all, the smaller the spatial unit, the smaller the total area required to capture all crimes.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#ranking-spatial-units","title":"Ranking Spatial Units","text":"<p>Lorenz curves typically will have an \\(x\\) axis that describes the proportion of spatial units, but it often makes sense to weight the axis, for example the proportion of land area, population, or some other factor. To understand the difference weighting makes, consider this example where we want to capture 50% of crime:</p> Index No crimes Area Density 0 1 10 0.1 1 1 10 0.1 2 2 25 0.08 3 0 5 0.0 <p>An unweighted ordering would rank index 2 highest, and 50% of crime can be accounted for one unit. However, a ranking that minimises area would use the first two units to capture 50% of crime in the smallest area (20 units, as opposed to 25 units for the unweighted case)</p> <p>Thus if we are using weights, the Lorenz curve plots the proportion of crimes as a function of the proportion of areas, ordered by the density of crime</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#examples-of-the-lorenz-curve-and-gini-coefficient-using-different-measures","title":"Examples of the Lorenz curve and Gini coefficient using different measures","text":"<p>Using a month's worth of incidents (~2700) of antisocial behaviour in West Yorkshire, we can construct the Lorenz curves for crimes aggregated by LSOA and by a square grid of roughly equivalent average size. In each graph the black dotted line represents the \"baseline\", meaning the number of crimes in each spatial unit if crimes were uniformly distributed. The Gini coefficient(1) is represented by the shaded areas:</p> <ol> <li> the value of Gini is actually twice the shaded area.</li> </ol> <p></p> <p>For uniform spatial units there is no difference between the cumulative count of units and the cumulative area of units (since they all have the same area), but this is definitely not the case for LSOAs, as can be seen in the graph on the right.</p> <p>In the left-hand graphs the dotted baseline curve represents an even distribution of crimes - in this case each spatial unit having the same number - approximately 1.9 - of crimes.</p> <p>Since LSOAs vary widely in area, a fixed number of crimes represents a wide variation in crime density, so in the right-hand graph we have computed the Gini coefficient using a baseline that represents an even distribution of crime density - i.e. the crime count is proportional to the size of the unit. This increases the Gini coefficient, suggesting there is no strong correlation between crime counts and unit area.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#what-about-population","title":"What about population?","text":"<p>So far we have compared cumulative area to a simple count of units, but we could also look at cumulative population (which is arguably more justifiable than area). The graphs below show the Lorenz curves for LSOAs (left) and the regular grid (right).</p> <p></p> <p>Because LSOAs do not have a high degree of variability in population, the Lorenz curve is very similar to the unweighted one above and the Gini coefficient.</p> <p>Conversely, because there is a very high degree of variability in population for a regular grid (some 15% of units actually have zero population) the Lorenz curve is less steep, and the Gini lower, suggesting there is a link between crime counts and resident population.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#so-what-baseline-should-we-use","title":"So what baseline should we use?","text":"<p>In the graphs below the Lorenz curves are plotted against various baselines - the curves you would get if crime was perfectly evenly distributed, in terms of either:</p> <ul> <li>\"unweighted\": the expected crime count is the same for each spatial unit</li> <li>\"area-weighted\": the expected crime count is proportional to the area of the spatial unit</li> <li>\"population-weighted\": the expected crime count is proportional to the population in the spatial unit</li> </ul> <p></p> <p>Firstly, since LSOAs don't vary widely in population, and grid area is constant with the exception of truncated units around the PFA edges, there is little difference between the unweighted baselines and the LSOA population-weighted and grid area-weighted baselines.</p> <p>Conversely, the other baseline curves are much closer to the observed data and seem to imply \"the observed concentration in crime in {LSOA, grid} can largely be explained by the variation the {area of, population in} the spatial unit\".</p> <p>And the table summarises the \"Gini\" values</p> Modified Gini Unweighted Area Population LSOA 0.61 -0.05 0.52 1200m grid 0.82 0.74 0.13","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#now-what","title":"Now what?","text":"<p>We've used the same raw crime and population data to create some very different representations of crime concentration, illustrating the subjectivity of these measures and the profound impact the choice of aggregation can have.</p> <p>However there's a more fundamental problem in the comparison against a perfectly even distribution of crime. In the next section we shall look at whether any of the baselines are a sensible reference value for measuring concentration.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#what-if-crime-isnt-concentrated","title":"What if crime isn't concentrated?","text":"<p>The distribution of crimes across spatial units is necessarily a discrete distribution, since you can't have fractional crimes. In the previous section the baseline represented ~1.9 crimes per unit, so is impossible - the closest we could get to this configuration is 2 crimes in ~90% of units and 1 in the remainder, which would add a \"kink\" to the baseline curve, reducing the shaded area and the Gini coefficient. When the baseline rate is less than one crime per unit (as is often the case), then we know some units must be crime-free, effectively squashing the baseline curve to the left and further reducing the shaded area.</p> <p>So in order to measure how concentrated crime actually is, we first need to establish what metrics we get when we know crime isn't concentrated. This is our null hypothesis and can be easily simulated with random sampling.</p> <p>Let's say we have \\(N\\) identical spatial units and our expectations is a total of \\(C\\) crimes. We consider crimes to be i.i.d. Poisson processes with intensity \\(\\lambda=C/N\\) for each spatial unit.</p> <p>In this model, our baseline of a perfectly even distribution is actually a (very) low entropy, (highly) improbable, state for the system. Firstly since we can't have fractional crimes, a perfectly even distribution isn't actually possible unless \\(C\\) is an integer multiple of \\(N\\).</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#how-likely-is-an-even-distribution","title":"How likely is an even distribution?","text":"<p>Taking the simplifying case where \\(C=N\\), the probability of exactly one crime in each unit is given by</p> \\[ p(\\text{uniform}) = N!/N^N \\] <p>which very quickly vanishes as the number of units \\(N\\) increases, so much so that if N is 750 or more, the probability cannot be represented in double precision arithmetic.</p> N p 10 0.0003 30 1e-12 100 9e-43 300 2e-129 1000 ~0 (not representable) <p>Since crime analysis would typically have \\(N\\gg 100\\) and also because typically \\(C&lt;N\\), this does not seem to be a suitable reference for a concentration calculation.</p> <p>When \\(C&lt;N\\), a quasi-uniform distribution would be \\(C\\) units containing 1 crime, and \\(N-C\\) units crime-free. However, although there is more degeneracy(1), this confguration is also an improbable low entropy state with the chance of occurrence given by</p> <ol> <li>Whilst there is only 1 way of putting 10 crimes in 10 different spatial units, there are over 30,000 ways of putting 5 crimes into 10 units with no unit having more than one crime</li> </ol> \\[ p(\\text{quasiuniform}) = \\frac{N!}{(N-C)!N^C} \\] <p>The table below illustrates some probabilities for various values of \\(C\\) and \\(N\\):</p> N C \\(\\lambda\\) p 300 30 0.1 0.2 300 60 0.2 0.002 300 150 0.5 1e-20 1000 100 0.1 0.006 1000 200 0.2 5e-10 1000 500 0.5 3e-67 <p>which again shows that this configuration is highly improbable for the typical values of \\(N\\) and \\(C\\) in crime analysis.</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#so-what-is-the-baseline","title":"So what is the baseline?","text":"<p>What we are looking for is a baseline that would closely match the Lorenz curve for i.i.d. randomly sampled crimes, which by construction are not concentrated. This would ensure that a Gini-like index using this baseline would have a value close to zero for i.i.d. events.</p> <p>The most probable, highest-entropy, state is actually given by the Poisson distribution itself.</p> <p>In other words, in all likelihood there will likely be a mixture of counts in each unit, depending on the intensity (\\(\\lambda=C/N\\)) of the Poisson process. The table below lists the expected number of units with a specific crime count, for 100 crimes at varying intensities:</p> N \\(\\lambda\\) empty 1 crime 2 crimes 3 crimes 4 crimes 1000 0.1 904.8 90.5 4.5 500 0.2 409.4 81.9 8.2 0.5 200 0.5 121.3 60.7 15.2 2.5 0.3 <p>On this basis the null hypothesis Lorenz curve, the Poisson baseline, is given by</p> \\[ L_0(x) = \\frac{1}{\\lambda}\\int_0^x{Q(p; \\lambda) dp} \\] <p>where \\(Q(p;\\lambda)\\) is the inverse CDF of the Poisson distribution. The curve is piecewise-linear and continuous and is described by the origin and the set of points</p> \\[ \\left\\{ (F(k; \\lambda), F(k-1; \\lambda)) \\mid k \\in \\mathbb{N}_0 \\right\\} \\] <p>where \\(F(k; \\lambda)\\) is the CDF.</p> <p>The figure below plots this curve and the naive baseline alongside real crime data and simulated (null hypothesis) crime data. Observe the following points:</p> <ul> <li>the actual crime data is clearly more concentrated than would be expected at random</li> <li>the Lorenz curve for the simulated crimes follows the Poisson baseline very closely</li> <li>the naive Gini value is represented by the combined blue and grey shaded areas</li> </ul> <p></p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/08/22/measuring-crime-concentration-part-1/#what-does-this-mean","title":"What does this mean?","text":"<p>Our assertion is that only the blue shaded area represents a level of concentration over and above purely random events, and in particular the grey shaded area (the \"excess\" Gini) cannot be be used to justify any structural mechanism - it arises purely from chance. Therefore, if our model of the Poisson baseline is valid and improves consistency over different spatial, temporal (and count) scaled, any measure of concentration should be made relative to the Poisson baseline.</p> <p>So far, we have only looked at uniform spatial units, Next, we will attempt to validate the model by comparing the distributions of actual crime data and data simulated under the null hypothesis, and seeing if we can extend it to heterogeneous units such as census geographies (OA, LSOA, and/or MSOA).</p>","tags":["Lorenz curve","Gini coefficient","Poisson distribution"]},{"location":"blog/2025/11/18/scaling-up/","title":"Scaling Up","text":"<p>As we're progressing with nationwide and force-specific hotspot determination we have had to reassess some of the tooling we've been using so far, particularly for presenting and disseminating results, and with a view to producing practical tools for practitioners and policymakers.</p> <p>We've started to hit performance limitations with geopandas so are switching a lot of the CPU-intensive spatial code to use an ephemeral duckdb instance with the spatial extension. This is exceptionally fast, able to load 3 years of national crime data (~18m incidents, England &amp; Wales) from over 1500 individual parquet files, and group the crimes into 200m hex cells (~1.5m) - all in well under 10 seconds.</p> <p>We've previously used Streamlit as a front-end (see here) but it's also not scaling well, proving somewhat inflexible and has compatibility issues with duckdb, so we're looking at alternatives. Later in the project we'll post a more definitive article on recommendations for the best (python) tooling, but in the meantime we're excited about the possibilities duckdb enables and want to share some progress...</p>","tags":["Crime hotspots","duckdb"]},{"location":"blog/2025/11/18/scaling-up/#embedded-interactive-hotspot-maps","title":"Embedded Interactive Hotspot Maps","text":"<p>Here are some illustrative results for a nationwide analysis of 3 crime types in the public data, covering the 3 year period up to September 2025.</p> <p>A rolling window of crime counts (1, 3, and 12 months) are aggregated onto a hex grid (200m side, ~350m height) and ranked. The top 0.1% of cells are recorded for each window. Finally, spatial units are then ranked by the number of times each spatial unit features in the top 0.1% over the 3 year period.</p> <p>In the interactive maps the hex cells are shaded according to the frequency they feature in the hotspots. Click on the tabs to switch crime type, and the links above each map to expand.</p> <p>Increasing the size of the rolling window has the effect of making the hotspots more stable. There are clear differences in the characteristics of different crimes, with \"Possession of weapons\", with relatively low counts, showing a lesser degree of concentration.</p> <p>(Note that Greater Manchester Police do not currently supply public crime data.)</p> Violence and Sexual OffencesAntisocial BehaviourPossession of Weapons <p> 1m hotspots </p> <p> 3m hotspots </p> <p> 12m hotspots </p> <p> 1m hotspots 3m hotspots </p> <p> 12m hotspots </p> <p> 1m hotspots </p> <p> 3m hotspots </p> <p> 12m hotspots </p>","tags":["Crime hotspots","duckdb"]},{"location":"blog/2025/08/18/why-is-all-this-maths/","title":"Why is all this maths important?","text":"","tags":["Explainer"]},{"location":"blog/2025/08/18/why-is-all-this-maths/#an-introduction-to-the-rationale-behind-our-analytical-approach","title":"An introduction to the rationale behind our analytical approach","text":"<p>This post is the first in a short blog series designed to accompany the analyses, documentation and reproducible code developed as part of our Safer Streets project. While the technical outputs are aimed at transparency and reusability, this series provides a more accessible commentary on the why behind the what - why we\u2019re doing what we\u2019re doing, and why it matters for policing and crime prevention practice.</p> <p></p> <p>In policing, every decision has an opportunity cost. Whether it's about where to send officers, which partnerships to invest in, or which issues to prioritise, resources are always finite. That means doing one thing comes at the expense of not doing something else. So the key question becomes: how can we allocate time, attention, and resources to the places and problems where they will make the most difference?</p> <p>A core part of the answer lies in understanding which problems are most frequent, most harmful, or have the greatest overall impact, and then targeting those problems with appropriate interventions. In other words: focus effort where it matters most.</p> <p>This is the logic that underpins hotspot policing - a well-established approach that recognises crime tends to concentrate in certain places, often at specific times. The evidence shows that targeting these micro-locations with the right type of action can reduce crime without simply shifting it elsewhere. It\u2019s a rare example of a policing strategy with strong and consistent empirical support.</p> <p>That sad, much of the research behind hotspot policing is based on high volume violent and property crimes - types of offending that have seen substantial declines since the mid 1990s. These types of offences often exhibit clear spatial and temporal patterning and are well suited to mapping, analysis and ultimatley targetted intervention techniques.</p> <p>Today\u2019s policing priorities are somewhat different. Under the Safer Streets programme, forces are focused on issues like:</p> <ul> <li>Violence against women and girls (VAWG)</li> <li>Knife crime </li> <li>Anti-social behaviour (ASB)</li> </ul> <p>These categories are complex, multi-faceted, and some may be underpinned by different dynamics than traditional property or violent crime.</p> <p>These challenges raise important questions:</p> <ul> <li>Do these offences concentrate in the same way as burglary, car crime or other forms of violence?  </li> <li>At what scale - street, neighbourhood, town - do patterns emerge?  </li> <li>Are those patterns stable over time, or highly variable?  </li> </ul> <p>At present, the evidence base for these questions is limited. That\u2019s why this project begins by returning to basics: descriptive analysis, guided by clear, reproducible methods, to explore how these priority crime types behave in space and time. This kind of foundational analysis is essential groundwork for any future efforts to reduce crime by targeting patterns effectively.</p> <p>And just as importantly, we need to recognise that different crime problems require different responses, and those responses must be scaled appropriately. Some interventions work at the level of an individual facility, street, or hotspot. Others make more sense at the community or borough level. A mismatch between the scale of the problem and the scale of the solution risks wasting precious time and money.</p> <p>So, why is all this maths important? Because when it comes to selecting and targetting crime prevention interventions at specific problems, doing the right thing, in the right place, at the right time starts with understanding what\u2019s really happening - and that understanding begins with data.</p> <p></p> <p>In the next post, we\u2019ll explore the different features of crime prevention interventions, from cost and scale to duration and speed of effect, and consider how these characteristics might be matched to the spatial and temporal patterns of offending. By doing so, we hope to better understand how to maximise the effectiveness of interventions in addressing the specific problems they\u2019re designed to tackle.</p>","tags":["Explainer"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/outputs/","title":"Outputs","text":""},{"location":"blog/category/methodology/","title":"Methodology","text":""},{"location":"blog/category/demographics/","title":"Demographics","text":""},{"location":"blog/category/general/","title":"General","text":""},{"location":"blog/page/2/","title":"Recent Posts","text":""},{"location":"blog/archive/2025/page/2/","title":"2025","text":""}]}